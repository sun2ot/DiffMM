{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载ui_dict.json\n",
    "with open('../datasets/yelp_tiny/ui_dict.json', 'r') as f:\n",
    "    ui_dict = json.load(f)\n",
    "\n",
    "# 创建用户和项目的映射\n",
    "user2id = {user: idx for idx, user in enumerate(ui_dict.keys())}\n",
    "item_set = set(item for items in ui_dict.values() for item in items.keys())\n",
    "item2id = {item: idx for idx, item in enumerate(item_set)}\n",
    "\n",
    "# 构建数据集并采样 1/3 的交互\n",
    "rows, cols, data = [], [], []\n",
    "for user, items in ui_dict.items():\n",
    "    for item in items.keys():\n",
    "        rows.append(user2id[user])\n",
    "        cols.append(item2id[item])\n",
    "        data.append(1)  # 所有评分置为1\n",
    "\n",
    "# 随机采样 1/3 的交互\n",
    "total_interactions = len(data)\n",
    "sample_size = total_interactions // 3\n",
    "sample_indices = np.random.choice(total_interactions, sample_size, replace=False)\n",
    "rows = [rows[i] for i in sample_indices]\n",
    "cols = [cols[i] for i in sample_indices]\n",
    "data = [data[i] for i in sample_indices]\n",
    "\n",
    "# 划分训练集、验证集和测试集\n",
    "indices = np.arange(len(data))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_idx, test_idx = train_test_split(test_idx, test_size=1/3, random_state=42)\n",
    "\n",
    "train_rows = [rows[i] for i in train_idx]\n",
    "train_cols = [cols[i] for i in train_idx]\n",
    "train_data = [data[i] for i in train_idx]\n",
    "\n",
    "val_rows = [rows[i] for i in val_idx]\n",
    "val_cols = [cols[i] for i in val_idx]\n",
    "val_data = [data[i] for i in val_idx]\n",
    "\n",
    "test_rows = [rows[i] for i in test_idx]\n",
    "test_cols = [cols[i] for i in test_idx]\n",
    "test_data = [data[i] for i in test_idx]\n",
    "\n",
    "# 构建稀疏矩阵\n",
    "train_matrix = coo_matrix((train_data, (train_rows, train_cols)))\n",
    "val_matrix = coo_matrix((val_data, (val_rows, val_cols)))\n",
    "test_matrix = coo_matrix((test_data, (test_rows, test_cols)))\n",
    "\n",
    "# 保存稀疏矩阵和映射文件\n",
    "os.makedirs('../mydatasets/yelp/', exist_ok=True)\n",
    "with open('../mydatasets/yelp/trnMat.pkl', 'wb') as f:\n",
    "    pickle.dump(train_matrix, f)\n",
    "with open('../mydatasets/yelp/valMat.pkl', 'wb') as f:\n",
    "    pickle.dump(val_matrix, f)\n",
    "with open('../mydatasets/yelp/tstMat.pkl', 'wb') as f:\n",
    "    pickle.dump(test_matrix, f)\n",
    "with open('../mydatasets/yelp/user2id.json', 'w') as f:\n",
    "    json.dump(user2id, f)\n",
    "with open('../mydatasets/yelp/item2id.json', 'w') as f:\n",
    "    json.dump(item2id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (38403, 20000)\n",
      "Number of non-zero entries: 133967\n",
      "Matrix shape: (38403, 20000)\n",
      "Number of non-zero entries: 38276\n",
      "Matrix shape: (38396, 19999)\n",
      "Number of non-zero entries: 19139\n",
      "Total number of interactions: 191382\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def ds_info(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        matrix = pickle.load(f)\n",
    "    print('Matrix shape:', matrix.shape)\n",
    "    its = matrix.nnz\n",
    "    print('Number of non-zero entries:', its)\n",
    "    return its\n",
    "\n",
    "files = ['../mydatasets/ifashion/trnMat.pkl',\n",
    "         '../mydatasets/ifashion/valMat.pkl',\n",
    "         '../mydatasets/ifashion/tstMat.pkl']\n",
    "all_its = 0\n",
    "for file in files:\n",
    "    all_its += ds_info(file)\n",
    "print('Total number of interactions:', all_its)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# 加载多模态特征文件\n",
    "image_embs = load_file('../datasets/yelp_tiny/item_image_emb.safetensors')\n",
    "text_embs = load_file('../datasets/yelp_tiny/item_text_embs.safetensors')\n",
    "\n",
    "# 筛选出交互数据中的项目并按照item_id顺序堆叠\n",
    "valid_items = set(item2id.keys())\n",
    "\n",
    "image_features = []\n",
    "text_features = []\n",
    "for item, idx in sorted(item2id.items(), key=lambda x: x[1]):\n",
    "    if item in valid_items:\n",
    "        image_features.append(image_embs[item].numpy())\n",
    "        text_features.append(text_embs[item].numpy())\n",
    "\n",
    "image_features = np.stack(image_features, axis=0)  # (item_num, dim)\n",
    "text_features = np.stack(text_features, axis=0)  # (item_num, dim)\n",
    "\n",
    "# 保存为.npy格式\n",
    "np.save('../mydatasets/yelp/image_feat.npy', image_features)\n",
    "np.save('../mydatasets/yelp/text_feat.npy', text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“diffmm (Python 3.10.16)”的单元格需要ipykernel包。\n",
      "\u001b[1;31m运行以下命令，将 \"ipykernel\" 安装到 Python 环境中。\n",
      "\u001b[1;31m命令: \"conda install -n diffmm ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def modal_info(path):\n",
    "    data = np.load(path)\n",
    "    print('Data shape:', data.shape)\n",
    "    print('Data type:', data.dtype)\n",
    "\n",
    "modal_info('../mydatasets/yelp/image_feat.npy')\n",
    "modal_info('../mydatasets/yelp/text_feat.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给师妹缩小的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25375/12671936.py:10: DeprecationWarning: Please use `coo_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.coo` namespace is deprecated.\n",
      "  return pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo: 647, 16170\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_mat(file_path) -> coo_matrix:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "trnMat = load_mat('../Datasets/sports/trnMat.pkl').tocsr()\n",
    "valMat = load_mat('../Datasets/sports/valMat.pkl').tocsr()\n",
    "tstMat = load_mat('../Datasets/sports/tstMat.pkl').tocsr()\n",
    "\n",
    "image_feat = np.load('../Datasets/sports/image_feat.npy')\n",
    "text_feat = np.load('../Datasets/sports/text_feat.npy')\n",
    "\n",
    "num_users = 18164\n",
    "num_items = 14514\n",
    "\n",
    "all_users = np.arange(trnMat.shape[0])\n",
    "all_items = np.arange(trnMat.shape[1])\n",
    "\n",
    "# 随机选择用户和项目\n",
    "selected_users = np.random.choice(all_users, num_users, replace=False)\n",
    "selected_items = np.random.choice(all_items, num_items, replace=False)\n",
    "print(f\"Demo: {selected_users[0]}, {selected_items[0]}\")\n",
    "\n",
    "train_sub = trnMat[selected_users, :][:, selected_items]\n",
    "valid_sub = valMat[selected_users, :][:, selected_items]\n",
    "test_sub = tstMat[selected_users, :][:, selected_items]\n",
    "\n",
    "# 筛选多模态特征\n",
    "image_feat_sub = image_feat[selected_items, :]\n",
    "text_feat_sub = text_feat[selected_items, :]\n",
    "\n",
    "os.makedirs('../Datasets/sports_tiny/', exist_ok=True)\n",
    "with open('../Datasets/sports_tiny/trnMat.pkl', 'wb') as f:\n",
    "    pickle.dump(train_sub, f)\n",
    "\n",
    "with open('../Datasets/sports_tiny/valMat.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_sub, f)\n",
    "\n",
    "with open('../Datasets/sports_tiny/tstMat.pkl', 'wb') as f:\n",
    "    pickle.dump(test_sub, f)\n",
    "\n",
    "np.save('../Datasets/sports_tiny/image_feat.npy', image_feat_sub)\n",
    "np.save('../Datasets/sports_tiny/text_feat.npy', text_feat_sub)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def ds_info(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        matrix = pickle.load(f)\n",
    "    print('Matrix shape:', matrix.shape)\n",
    "    its = matrix.nnz\n",
    "    print('Number of non-zero entries:', its)\n",
    "    return its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (18164, 14514)\n",
      "Number of non-zero entries: 88175\n",
      "Matrix shape: (18164, 14514)\n",
      "Number of non-zero entries: 16132\n",
      "Matrix shape: (18164, 14514)\n",
      "Number of non-zero entries: 15401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15401"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info('../Datasets/sports_tiny/trnMat.pkl')\n",
    "ds_info('../Datasets/sports_tiny/valMat.pkl')\n",
    "ds_info('../Datasets/sports_tiny/tstMat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查前后数据是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48689997 0.         2.39369988 ... 0.         0.         0.43309999]\n",
      "[1.48689997 0.         2.39369988 ... 0.         0.         0.43309999]\n"
     ]
    }
   ],
   "source": [
    "origin = np.load('../Datasets/sports/image_feat.npy')\n",
    "print(origin[16170])\n",
    "new = np.load('../Datasets/sports_tiny/image_feat.npy')\n",
    "print(new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (35598, 18357)\n",
      "Number of non-zero entries: 218409\n",
      "Matrix shape: (35598, 18357)\n",
      "Number of non-zero entries: 40029\n",
      "Matrix shape: (35598, 18357)\n",
      "Number of non-zero entries: 37899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25375/1411155986.py:5: DeprecationWarning: Please use `coo_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.coo` namespace is deprecated.\n",
      "  matrix = pickle.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37899"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info('../Datasets/sports/trnMat.pkl')\n",
    "ds_info('../Datasets/sports/valMat.pkl')\n",
    "ds_info('../Datasets/sports/tstMat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
