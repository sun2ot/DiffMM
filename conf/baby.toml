[base]
latdim = 64 # Embedding size
topk = 20
gpu = "0"
seed = 114514 # Random seed
denoise_dim = "[1024]" # embedding size for denoise layer input/output 
d_emb_size = 10 # time embedding size for diffusion step

# Transformation type: 0 = Project Matrix, 1 = Linear, 2 = allrecipes
trans = 1

# Contrastive learning method: 0 = m vs m, 1 = m vs main
cl_method = 1

# ------------------------------------------------------------

[data]
name = "baby" # Dataset name

# ------------------------------------------------------------

[hyper] # Hyperparameters for the model
modal_cl_temp = 0.5 # Temperature in contrastive learning
modal_cl_rate = 0.2 # Weight for contrastive learning
cross_cl_temp = 0.2
cross_cl_rate = 0.2
keepRate = 1 # Ratio of edges to keep (baby 1)

noise_scale = 0.1 # Noise scale
noise_min = 0.0001 # Minimum noise
noise_max = 0.02 # Maximum noise
steps = 5 # Number of steps

e_loss = 0.01 # Edge loss (baby 0.01)
residual_weight = 0.5  # RIS lambda
modal_adj_weight = 0.2

sampling_steps = 5 # Initial sampling steps for the inverse diffusion process
rebuild_k = 1 # Use top k (probabilities) items to rebuild UI matrix

# ------------------------------------------------------------

[train]
lr = 0.01 # Learning rate
batch = 1024 # Batch size
test_batch = 256 # Number of users in a testing batch
reg = 1e-5 # Weight decay regularizer
epoch = 100 # Number of epochs
tstEpoch = 1 # Number of epochs to test while training
gnn_layer = 1 # Number of GNN layers
norm = false # Whether to apply normalization
sampling_noise = false # Whether to use sampling noise